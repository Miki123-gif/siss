{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-18 20:22:58--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "正在解析主机 repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
      "正在连接 repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 301 Moved Permanently\n",
      "位置：https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [跟随至新的 URL]\n",
      "--2020-08-18 20:23:02--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "正在解析主机 repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
      "正在连接 repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度：93052469 (89M) [application/x-sh]\n",
      "正在保存至: “Miniconda3-latest-Linux-x86_64.sh”\n",
      "\n",
      "16% [=====>                                 ] 15,456,713   246KB/s 剩余 3m 48s   ^C\n"
     ]
    }
   ],
   "source": [
    "# https://blog.csdn.net/weixin_43840215/article/details/89599559\n",
    "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "!chmod 777 Miniconda3-latest-Linux-x86_64.sh\n",
    "!sh Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: 未找到命令\n",
      "/bin/bash: conda: 未找到命令\n",
      "/bin/bash: conda: 未找到命令\n",
      "/bin/bash: conda: 未找到命令\n",
      "/bin/bash: conda: 未找到命令\n",
      "/bin/bash: conda: 未找到命令\n"
     ]
    }
   ],
   "source": [
    "# 上面链接都是https的。然而我在下载的时候报错了。应该把s删掉\n",
    "!conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n",
    "!conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/\n",
    "!conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\n",
    "!conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/\n",
    "!conda config --set show_channel_urls yes \n",
    "!conda config --get channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# https://blog.csdn.net/zzq060143/article/details/88042075\n",
    "# 请仔细参考这个，添加镜像\n",
    "!conda install pytorch torchvision cudatoolkit=10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/miniconda3/bin/python'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# 由于我是使用conda安装的，默认使用的是conda的base环境。\n",
    "# 所以其他环境是使用不了torch的\n",
    "# 先要激活conda环境，并且退出当前的virtualenv\n",
    "\n",
    "!deactivate # 在当前环境直接输入这个指令即可\n",
    "!source miniconda3/bin/activate\n",
    "!conda jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(8).reshape(4,2),columns=['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(np.arange(4,12).reshape(4,2),columns=['c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以使用这种方法同时修改训练集和测试集\n",
    "all_data = [data, test]\n",
    "for i in all_data:\n",
    "    i.iloc[:,1] = np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看电脑的显卡能不能使用\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两个重要函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(torch) dir可以查看有哪些可用的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(torch.cuda) help告诉我们如何使用这个函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch的学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch类型数据\n",
    "# numpy类型数据\n",
    "\n",
    "np_data = np.arange(8).reshape(2,4)\n",
    "np_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在torch中，如果是一个数字，就是0维，**在torch中没有string类型的数据**。如果要表示字符串类型，可以使用one-hot方法\n",
    "\n",
    "然而在实际的生活中，英语单词有上万多个，我们单独靠one-hot，会使得矩阵非常稀疏。而且不能表达出单词的近似程度。\n",
    "\n",
    "所以one-hot编码是有缺陷的，所以人们开发出来其他的方式来编码，编码叫Embedding， 里面有w2v， glove方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "floattensor  32\n",
    "\n",
    "doubletensor 64\n",
    "\n",
    "longtensor 64\n",
    "\n",
    "inttensor 32\n",
    "\n",
    "bytetensor 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "a.type() # 返回的是具体的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回的是基本的数据类型\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 判断诗句类型是不是一致\n",
    "isinstance(a, torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# 将数据放到GPU的时候数据类型但是又会发生变化\n",
    "\n",
    "isinstance(data, torch.cuda.FloatTensor)\n",
    "\n",
    "data.cuda() # 将数据放到GPU上\n",
    "\n",
    "isinstance(data, torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0维的有什么用呢？通常loss就是0维的，也就是标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 纬度为0的标量，维度为0就是标量\n",
    "torch.tensor(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.).dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度为1的张量有什么用呢？\n",
    "\n",
    "在神经元中，我们通常要设置偏置。ax+b中b就是。我们用一维张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 dim []\n",
    "torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-6daa886b8cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor([1,1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0798e-24,  4.5891e-41, -1.5148e+00],\n",
       "        [ 3.0624e-41,         nan,  0.0000e+00]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 dim [[],[]],多个列表嵌套就是2维\n",
    "\n",
    "a = torch.FloatTensor(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0798e-24,  4.5891e-41, -1.3108e+00]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.FloatTensor(1,3) # 注意这是随机生成的\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0798e-24,  4.5891e-41, -1.5225e+00],\n",
       "         [ 3.0624e-41,  4.4842e-44,  0.0000e+00]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 dim [[[]],[[]]]\n",
    "# 3 dim有什么用呢？他们的使用场景非常广泛\n",
    "# 比如在nlp中，一句话有10个单词，每个单词用向量表示这句话就可以用2维tensor表示[10, 100]/假如每个单词用100个表示\n",
    "# 假如现在有20句话，用3 dim表示[20,10,100]\n",
    "c = torch.FloatTensor(1,2,3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0798e-24,  4.5891e-41, -1.5225e+00],\n",
       "        [ 3.0624e-41,  4.4842e-44,  0.0000e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0798e-24,  4.5891e-41, -1.5225e+00])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更高维 4dim，5dim\n",
    "# [2,3,29,29]\n",
    "# 上面2表示照片数量，3表示每个照片颜色通道RGB，29*29表示长宽\n",
    "# 注意一个维度，只能用来描述一种特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 未初始化的tensor，不要直接使用未初始化的数据，输入到其他地方\n",
    "# 未初始化只是为了申请内存，然后赋值给他。\n",
    "# 如果直接将未初始化的数据喂到其他地方。因为值是随机的。有些值是无穷大。容易出现问题\n",
    "\n",
    "torch.FloatTensor(2,2,2) # 未初始化的数据，其内部的值是随机的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8526, 0.3177, 0.6964],\n",
       "        [0.0450, 0.3220, 0.9346],\n",
       "        [0.5983, 0.3297, 0.9744]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机初始化\n",
    "torch.rand(3,3) # 初始化的值是在0-1之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4837, 0.7445, 0.2592],\n",
       "         [0.3884, 0.1026, 0.6049],\n",
       "         [0.4994, 0.7637, 0.4178]],\n",
       "\n",
       "        [[0.3952, 0.8937, 0.4947],\n",
       "         [0.4957, 0.4705, 0.9129],\n",
       "         [0.7484, 0.5479, 0.8227]],\n",
       "\n",
       "        [[0.6375, 0.6115, 0.6347],\n",
       "         [0.4693, 0.2609, 0.5884],\n",
       "         [0.2203, 0.5070, 0.4755]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,3,3)\n",
    "c = torch.rand_like(a) # 读取一个tensor的shape，然后传给rand like。like相似\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 9],\n",
       "        [3, 9]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,10,[2,2]) # 在最大和最小值区间生成随机数，第三个参数是指定shape，以列表的形式传入，不包括最大值10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8897,  1.5054,  0.1210],\n",
       "        [-0.1361,  0.3104, -0.7207],\n",
       "        [ 1.0253, -1.2426,  0.5322]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,3) # 生成一个正太分布的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([2,3],0.0,) # 好像只能生成float类型的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([],3.) # 创建一个标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,10,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
       "         8.8889, 10.0000])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,10,10) # 等份切"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 3, 1, 8, 0, 7, 6, 9, 5])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10) # 生成一个随机的序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9975, 0.8395],\n",
       "         [0.4927, 0.9900],\n",
       "         [0.3013, 0.9192]],\n",
       "\n",
       "        [[0.7212, 0.0430],\n",
       "         [0.5839, 0.6931],\n",
       "         [0.6613, 0.2377]]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(2,3,2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9975, 0.8395],\n",
       "        [0.4927, 0.9900],\n",
       "        [0.3013, 0.9192]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # 索引的是第0个3，2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9975, 0.8395])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8395)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975, 0.8395],\n",
      "        [0.4927, 0.9900],\n",
      "        [0.3013, 0.9192]])\n",
      "tensor([[0.7212, 0.0430],\n",
      "        [0.5839, 0.6931],\n",
      "        [0.6613, 0.2377]])\n"
     ]
    }
   ],
   "source": [
    "for each in data: # 居然可以遍历\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9975, 0.8395],\n",
       "         [0.4927, 0.9900],\n",
       "         [0.3013, 0.9192]]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切片\n",
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1].dim() # 依旧是三维的 # 这里是对第一个通道索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9975, 0.8395]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1,:1] # 还可以对第二个通道索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3013, 0.9192]]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1,-1:] # -1开始表示只选取末尾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9975, 0.8395],\n",
       "         [0.4927, 0.9900],\n",
       "         [0.3013, 0.9192]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1:2,:,:] # 甚至可以隔行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9250, 0.9249, 0.6874],\n",
       "         [0.3065, 0.2696, 0.8503],\n",
       "         [0.0577, 0.7079, 0.6500]],\n",
       "\n",
       "        [[0.1635, 0.2214, 0.2830],\n",
       "         [0.1326, 0.0176, 0.5144],\n",
       "         [0.7082, 0.1147, 0.5520]],\n",
       "\n",
       "        [[0.0726, 0.4157, 0.1398],\n",
       "         [0.6775, 0.5979, 0.3828],\n",
       "         [0.5380, 0.3950, 0.5863]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(3,3,3)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "index_select() received an invalid combination of arguments - got (int, list), but expected one of:\n * (name dim, Tensor index)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m)\n * (int dim, Tensor index)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-0c20a8b73951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: index_select() received an invalid combination of arguments - got (int, list), but expected one of:\n * (name dim, Tensor index)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m)\n * (int dim, Tensor index)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mlist\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "data.index_select(0,[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function index_select:\n",
      "\n",
      "index_select(...)\n",
      "    index_select(input, dim, index, out=None) -> Tensor\n",
      "    \n",
      "    Returns a new tensor which indexes the :attr:`input` tensor along dimension\n",
      "    :attr:`dim` using the entries in :attr:`index` which is a `LongTensor`.\n",
      "    \n",
      "    The returned tensor has the same number of dimensions as the original tensor\n",
      "    (:attr:`input`).  The :attr:`dim`\\ th dimension has the same size as the length\n",
      "    of :attr:`index`; other dimensions have the same size as in the original tensor.\n",
      "    \n",
      "    .. note:: The returned tensor does **not** use the same storage as the original\n",
      "              tensor.  If :attr:`out` has a different shape than expected, we\n",
      "              silently change it to the correct shape, reallocating the underlying\n",
      "              storage if necessary.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        dim (int): the dimension in which we index\n",
      "        index (LongTensor): the 1-D tensor containing the indices to index\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.randn(3, 4)\n",
      "        >>> x\n",
      "        tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n",
      "                [-0.4664,  0.2647, -0.1228, -1.1068],\n",
      "                [-1.1734, -0.6571,  0.7230, -0.6004]])\n",
      "        >>> indices = torch.tensor([0, 2])\n",
      "        >>> torch.index_select(x, 0, indices)\n",
      "        tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n",
      "                [-1.1734, -0.6571,  0.7230, -0.6004]])\n",
      "        >>> torch.index_select(x, 1, indices)\n",
      "        tensor([[ 0.1427, -0.5414],\n",
      "                [-0.4664, -0.1228],\n",
      "                [-1.1734,  0.7230]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.index_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看pytorch基础教程，第19课时。完成上面最近的select_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将array转化成tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data = torch.from_numpy(np_data)\n",
    "torch_data # 将np数据转化成tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将tensor转化成array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_array = torch_data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些常用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [1,9]\n",
    "data2 = [[1,2],[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3da3b29173b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "torch.mean(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在torch和numpy中，前者最好先将数据转化成tensor的形式，后者最好转化成array的形式\n",
    "# 这样转换后，才好通过运算\n",
    "array1 = np.array(data1)\n",
    "array2 = np.array(data2)\n",
    "tensor1 = torch.FloatTensor(data1)\n",
    "tensor2 = torch.FloatTensor(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8415,  0.4121, -0.8415,  0.1411])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sin(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 9., 1., 3.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2.dot(array2) # 矩阵的乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 39])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2.dot(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 18],\n",
       "       [ 3, 36]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1*array2 # 甚至可以按位运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 9.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(82.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.dot(tensor1) # 1*1+9*9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用torch完成Minist手写数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('mnist data', train=True, download=True, transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.13,),(0.3,))]\n",
    "    )),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('mnist data', train=False, download=True, transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.13,),(0.3,))]\n",
    "    )),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1, 28, 28])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape\n",
    "# 每个batch有500个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # 一共有三层网络，输入是28*28\n",
    "        # 第二层是256\n",
    "        # 第三层是64\n",
    "        # 最后输出是10，因为有0-9个数字。第二层和第三层的神经元数都是自己设定的\n",
    "        self.func1 = nn.Linear(28*28, 256)\n",
    "        self.func2 = nn.Linear(256, 64)\n",
    "        self.func3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x:[batch, 1,28,28]\n",
    "        # h1 = relu(xw1+b1)\n",
    "        x = F.relu(self.func1(x))\n",
    "        x = F.relu(self.func2(x))\n",
    "        x = self.func3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28]) torch.Size([500])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d94253743052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmes_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum = 0.9)\n",
    "\n",
    "for epoch in range(3): # 对数据集，迭代3遍\n",
    "    for batch_index, (x,y) in enumerate(train_loader): # 开始对数据集的每个batch迭代第一遍\n",
    "        print(x.shape,y.shape)\n",
    "        x = x.view(x.size(0), 28*28)\n",
    "        out = net(x)\n",
    "        y_onehot = one_hot(y)\n",
    "        loss = F.mes_loss(out, y_onehot)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_inde % 10 == 0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "171px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
